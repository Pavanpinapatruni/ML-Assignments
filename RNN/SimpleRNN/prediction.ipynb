{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b55ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FPK1COB\\Documents\\Learning\\ML-assignments\\ML-Assignments\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4815ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ddf04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,027</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,313,027\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,025</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,313,025\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pre-trained model with Relu activation\n",
    "model = load_model('simple_rnn_imdb.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbb61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d97ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to decode reviews\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Function to preprocess user input\n",
    "def preprocess_review(review, maxlen=500):\n",
    "    # Simple preprocessing: lowercase and split by spaces\n",
    "    # Better preprocessing: handle punctuation and lowercase\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    review = re.sub(r'[^a-zA-Z\\s]', '', review.lower())\n",
    "    words = review.split()\n",
    "    encoded_review = []\n",
    "    for word in words:\n",
    "        index = word_index.get(word, 2)  # 2 is the index for 'unknown' words\n",
    "        encoded_review.append(index + 3)  # Offset by 3 for special tokens\n",
    "    padded_review = sequence.pad_sequences([encoded_review], maxlen=maxlen)\n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be7070",
   "metadata": {},
   "source": [
    "```python\n",
    "  for word in words:\n",
    "        index = word_index.get(word, 2)  # 2 is the index for 'unknown' words\n",
    "        encoded_review.append(index + 3)  # Offset by 3 for special tokens\n",
    "```\n",
    "\n",
    "* Each word is converted to its corresponding integer index using the IMDB word index dictionary\n",
    "* If a word isn't found in the dictionary, it gets index 2 (unknown word token)\n",
    "* Adds 3 to each index to account for reserved special tokens:\n",
    "  * Index 0: Padding\n",
    "  * Index 1: Start of sequence\n",
    "  * Index 2: Unknown word\n",
    "  * Index 3+: Actual vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction function\n",
    "\n",
    "def predict_review(review):\n",
    "    \n",
    "    preprocessed_review = preprocess_review(review)\n",
    "\n",
    "    prediction = model.predict(preprocessed_review)\n",
    "\n",
    "    sentiment = 'Positive' if prediction[0][0] >= 0.5 else 'Negative'\n",
    "\n",
    "    return sentiment, prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d27dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Review: The movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Sentiment: Positive (Confidence: 0.6722)\n"
     ]
    }
   ],
   "source": [
    "# User Input and Prediction\n",
    "# Example review\n",
    "# example_review = \"The movie was fantastic! I really loved it and would watch it again.\"\n",
    "example_review = \"The movie was fantastic! The acting was great and the plot was thrilling.\"\n",
    "sentiment, confidence = predict_review(example_review)\n",
    "\n",
    "print(f'Review: {example_review}')\n",
    "print(f'Sentiment: {sentiment} (Confidence: {confidence:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0827a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRECTED PREDICTION FUNCTION ===\n",
      "Review: The movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Prediction: Positive (Confidence: 0.6722)\n",
      "\n",
      "Review: This movie is terrible and boring.\n",
      "Prediction: Negative (Confidence: 0.0110)\n",
      "\n",
      "Review: Amazing film with great acting!\n",
      "Prediction: Positive (Confidence: 0.7480)\n",
      "\n",
      "Review: I loved every minute of it.\n",
      "Prediction: Negative (Confidence: 0.1817)\n",
      "\n",
      "Review: Worst movie ever made.\n",
      "Prediction: Negative (Confidence: 0.2046)\n",
      "\n",
      "Review: Absolutely brilliant and entertaining.\n",
      "Prediction: Positive (Confidence: 0.6146)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's create the corrected prediction functions\n",
    "def predict_review_corrected(review):\n",
    "    \"\"\"Updated prediction function with improved preprocessing\"\"\"\n",
    "    preprocessed_review = preprocess_review(review)\n",
    "    prediction = model.predict(preprocessed_review, verbose=0)\n",
    "    sentiment = 'Positive' if prediction[0][0] >= 0.5 else 'Negative'\n",
    "    return sentiment, prediction[0][0]\n",
    "\n",
    "# Test the corrected function\n",
    "print(\"=== CORRECTED PREDICTION FUNCTION ===\")\n",
    "test_reviews = [\n",
    "    \"The movie was fantastic! The acting was great and the plot was thrilling.\",\n",
    "    \"This movie is terrible and boring.\",\n",
    "    \"Amazing film with great acting!\",\n",
    "    \"I loved every minute of it.\",\n",
    "    \"Worst movie ever made.\",\n",
    "    \"Absolutely brilliant and entertaining.\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    sentiment, confidence = predict_review_corrected(review)\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Prediction: {sentiment} (Confidence: {confidence:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037bb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
