{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd068ab5",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b55cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'runner', 'runs', 'happily', 'happiness', 'happy', 'flies', 'flying', 'fly', 'denied', 'denying', 'denies', 'lying', 'lied', 'lies', 'relational', 'relation', 'relations']\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    \"running\", \"runner\", \"runs\",\n",
    "    \"happily\", \"happiness\", \"happy\",\n",
    "    \"flies\", \"flying\", \"fly\",\n",
    "    \"denied\", \"denying\", \"denies\",\n",
    "    \"lying\", \"lied\", \"lies\",\n",
    "    \"relational\", \"relation\", \"relations\"\n",
    "]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514cd34c",
   "metadata": {},
   "source": [
    "## Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11980992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed3995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac8dc371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: running --> Stemmed: run\n",
      "Original: runner --> Stemmed: runner\n",
      "Original: runs --> Stemmed: run\n",
      "Original: happily --> Stemmed: happili\n",
      "Original: happiness --> Stemmed: happi\n",
      "Original: happy --> Stemmed: happi\n",
      "Original: flies --> Stemmed: fli\n",
      "Original: flying --> Stemmed: fli\n",
      "Original: fly --> Stemmed: fli\n",
      "Original: denied --> Stemmed: deni\n",
      "Original: denying --> Stemmed: deni\n",
      "Original: denies --> Stemmed: deni\n",
      "Original: lying --> Stemmed: lie\n",
      "Original: lied --> Stemmed: lie\n",
      "Original: lies --> Stemmed: lie\n",
      "Original: relational --> Stemmed: relat\n",
      "Original: relation --> Stemmed: relat\n",
      "Original: relations --> Stemmed: relat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    stemmed_word = porter_stemmer.stem(word)\n",
    "    print(f\"Original: {word} --> Stemmed: {stemmed_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40fe05",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef2704c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8004b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "076d6a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('turnable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "486ff981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ableturn'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ableturnable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c86d5e",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1351307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "535117ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d99d6ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: running --> Stemmed: run\n",
      "Original: runner --> Stemmed: runner\n",
      "Original: runs --> Stemmed: run\n",
      "Original: happily --> Stemmed: happili\n",
      "Original: happiness --> Stemmed: happi\n",
      "Original: happy --> Stemmed: happi\n",
      "Original: flies --> Stemmed: fli\n",
      "Original: flying --> Stemmed: fli\n",
      "Original: fly --> Stemmed: fli\n",
      "Original: denied --> Stemmed: deni\n",
      "Original: denying --> Stemmed: deni\n",
      "Original: denies --> Stemmed: deni\n",
      "Original: lying --> Stemmed: lie\n",
      "Original: lied --> Stemmed: lie\n",
      "Original: lies --> Stemmed: lie\n",
      "Original: relational --> Stemmed: relat\n",
      "Original: relation --> Stemmed: relat\n",
      "Original: relations --> Stemmed: relat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    stemmed_word = porter_stemmer.stem(word)\n",
    "    print(f\"Original: {word} --> Stemmed: {stemmed_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e593ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sportingly   | Porter: sportingli | Snowball: sport\n",
      "fairly       | Porter: fairli     | Snowball: fair\n",
      "occasionally | Porter: occasion   | Snowball: occasion\n",
      "goes         | Porter: goe        | Snowball: goe\n"
     ]
    }
   ],
   "source": [
    "examples = [\"sportingly\", \"fairly\", \"occasionally\", \"goes\"]\n",
    "\n",
    "for word in examples:\n",
    "    porter_result = porter_stemmer.stem(word)\n",
    "    snowball_result = snowball.stem(word)\n",
    "    print(f\"{word:12} | Porter: {porter_result:10} | Snowball: {snowball_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdccbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
