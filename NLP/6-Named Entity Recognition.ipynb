{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7225de9",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "Named Entity Recognition is a natural language processing task that identifies and classifies named entities in text into predefined categories such as:\n",
    "\n",
    "- **PERSON**: Names of people\n",
    "- **ORGANIZATION**: Companies, agencies, institutions\n",
    "- **LOCATION**: Countries, cities, states\n",
    "- **DATE**: Absolute or relative dates or periods\n",
    "- **TIME**: Times smaller than a day\n",
    "- **MONEY**: Monetary values\n",
    "- **PERCENT**: Percentage values\n",
    "- **FACILITY**: Buildings, airports, highways, bridges\n",
    "- **GPE**: Geopolitical entities (countries, cities, states)\n",
    "\n",
    "## Why is NER Important?\n",
    "- Information extraction from unstructured text\n",
    "- Building knowledge graphs\n",
    "- Question answering systems\n",
    "- Content recommendation\n",
    "- Social media analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0d3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "\n",
    "# Download required NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea0aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text:\n",
      "\n",
      "Apple Inc. is an American multinational technology company headquartered in Cupertino, California. \n",
      "The company was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne on April 1, 1976. \n",
      "Tim Cook is the current CEO who took over from Steve Jobs in August 2011. \n",
      "Apple's headquarters, known as Apple Park, opened in April 2017 and cost approximately $5 billion to build.\n",
      "The company's market capitalization reached $3 trillion in January 2022, making it the most valuable company in the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample text for Named Entity Recognition\n",
    "text = \"\"\"\n",
    "Apple Inc. is an American multinational technology company headquartered in Cupertino, California. \n",
    "The company was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne on April 1, 1976. \n",
    "Tim Cook is the current CEO who took over from Steve Jobs in August 2011. \n",
    "Apple's headquarters, known as Apple Park, opened in April 2017 and cost approximately $5 billion to build.\n",
    "The company's market capitalization reached $3 trillion in January 2022, making it the most valuable company in the world.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sample Text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451980d",
   "metadata": {},
   "source": [
    "## Method 1: Using NLTK for Named Entity Recognition\n",
    "\n",
    "NLTK provides a built-in named entity recognizer that uses the `ne_chunk()` function. This method:\n",
    "1. Tokenizes the text into words\n",
    "2. Performs Part-of-Speech tagging\n",
    "3. Identifies named entities using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a746be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c57d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Named Entity Recognition Results:\n",
      "==================================================\n",
      "Entity: Apple                | Type: PERSON\n",
      "Entity: Inc.                 | Type: ORGANIZATION\n",
      "Entity: American             | Type: GPE\n",
      "Entity: Cupertino            | Type: GPE\n",
      "Entity: California           | Type: GPE\n",
      "Entity: Steve Jobs           | Type: PERSON\n",
      "Entity: Steve Wozniak        | Type: PERSON\n",
      "Entity: Ronald Wayne         | Type: PERSON\n",
      "Entity: Tim Cook             | Type: PERSON\n",
      "Entity: Steve Jobs           | Type: PERSON\n",
      "Entity: Apple                | Type: PERSON\n",
      "Entity: Apple Park           | Type: PERSON\n",
      "\n",
      "Total named entities found: 12\n"
     ]
    }
   ],
   "source": [
    "# NLTK Named Entity Recognition\n",
    "def nltk_ner(text):\n",
    "    # Step 1: Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 2: Perform Part-of-Speech tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Step 3: Named Entity Recognition\n",
    "    entities = ne_chunk(pos_tags)\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Apply NLTK NER to our sample text\n",
    "nltk_entities = nltk_ner(text)\n",
    "\n",
    "print(\"NLTK Named Entity Recognition Results:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Extract and display named entities\n",
    "named_entities = []\n",
    "for entity in nltk_entities:\n",
    "    if hasattr(entity, 'label'):  # It's a named entity\n",
    "        entity_name = ' '.join([child[0] for child in entity])\n",
    "        entity_label = entity.label()\n",
    "        named_entities.append((entity_name, entity_label))\n",
    "        print(f\"Entity: {entity_name:20} | Type: {entity_label}\")\n",
    "\n",
    "print(f\"\\nTotal named entities found: {len(named_entities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a3223",
   "metadata": {},
   "source": [
    "## Method 2: Using spaCy for Named Entity Recognition\n",
    "\n",
    "spaCy is a more advanced NLP library that provides better accuracy for NER tasks. It offers:\n",
    "- More entity types\n",
    "- Better accuracy\n",
    "- Built-in visualization tools\n",
    "- Industrial-strength performance\n",
    "\n",
    "**Note**: You need to install spaCy and download the English model:\n",
    "```bash\n",
    "pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54a8ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy Named Entity Recognition Results:\n",
      "============================================================\n",
      "Entity: Apple Inc.           | Type: ORG          | Description: Companies, agencies, institutions, etc.\n",
      "Entity: American             | Type: NORP         | Description: Nationalities or religious or political groups\n",
      "Entity: Cupertino            | Type: GPE          | Description: Countries, cities, states\n",
      "Entity: California           | Type: GPE          | Description: Countries, cities, states\n",
      "Entity: Steve Jobs           | Type: PERSON       | Description: People, including fictional\n",
      "Entity: Steve Wozniak        | Type: PERSON       | Description: People, including fictional\n",
      "Entity: Ronald Wayne         | Type: PERSON       | Description: People, including fictional\n",
      "Entity: April 1, 1976        | Type: DATE         | Description: Absolute or relative dates or periods\n",
      "Entity: Tim Cook             | Type: PERSON       | Description: People, including fictional\n",
      "Entity: Steve Jobs           | Type: PERSON       | Description: People, including fictional\n",
      "Entity: August 2011          | Type: DATE         | Description: Absolute or relative dates or periods\n",
      "Entity: Apple                | Type: ORG          | Description: Companies, agencies, institutions, etc.\n",
      "Entity: Apple Park           | Type: ORG          | Description: Companies, agencies, institutions, etc.\n",
      "Entity: April 2017           | Type: DATE         | Description: Absolute or relative dates or periods\n",
      "Entity: approximately $5 billion | Type: MONEY        | Description: Monetary values, including unit\n",
      "Entity: $3 trillion          | Type: MONEY        | Description: Monetary values, including unit\n",
      "Entity: January 2022         | Type: DATE         | Description: Absolute or relative dates or periods\n",
      "\n",
      "Total named entities found: 17\n"
     ]
    }
   ],
   "source": [
    "# spaCy Named Entity Recognition\n",
    "try:\n",
    "    # Load the English language model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    print(\"spaCy Named Entity Recognition Results:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Extract and display named entities\n",
    "    spacy_entities = []\n",
    "    for ent in doc.ents:\n",
    "        spacy_entities.append((ent.text, ent.label_))\n",
    "        print(f\"Entity: {ent.text:20} | Type: {ent.label_:12} | Description: {spacy.explain(ent.label_)}\")\n",
    "    \n",
    "    print(f\"\\nTotal named entities found: {len(spacy_entities)}\")\n",
    "    \n",
    "except OSError:\n",
    "    print(\"spaCy English model not found!\")\n",
    "    print(\"Please install it using: python -m spacy download en_core_web_sm\")\n",
    "except ImportError:\n",
    "    print(\"spaCy not installed!\")\n",
    "    print(\"Please install it using: pip install spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597fc31",
   "metadata": {},
   "source": [
    "## Method 3: Custom Entity Extraction\n",
    "\n",
    "You can also create custom functions to extract specific types of entities using regular expressions or pattern matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa6c7a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Entity Extraction Results:\n",
      "========================================\n",
      "\n",
      "DATES:\n",
      "  - April 1, 1976\n",
      "\n",
      "MONEY:\n",
      "  - $5 billion\n",
      "  - $3 trillion\n",
      "\n",
      "PERCENTAGES: None found\n",
      "\n",
      "EMAILS: None found\n",
      "\n",
      "PHONE_NUMBERS: None found\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_custom_entities(text):\n",
    "    \"\"\"\n",
    "    Extract specific types of entities using regular expressions\n",
    "    \"\"\"\n",
    "    entities = {\n",
    "        'dates': [],\n",
    "        'money': [],\n",
    "        'percentages': [],\n",
    "        'emails': [],\n",
    "        'phone_numbers': []\n",
    "    }\n",
    "    \n",
    "    # Extract dates (various formats)\n",
    "    date_patterns = [\n",
    "        r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',  # MM/DD/YYYY\n",
    "        r'\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b',  # YYYY-MM-DD\n",
    "        r'\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},?\\s+\\d{4}\\b',  # Month DD, YYYY\n",
    "        r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2},?\\s+\\d{4}\\b'  # Abbreviated months\n",
    "    ]\n",
    "    \n",
    "    for pattern in date_patterns:\n",
    "        entities['dates'].extend(re.findall(pattern, text, re.IGNORECASE))\n",
    "    \n",
    "    # Extract money amounts\n",
    "    money_pattern = r'\\$\\d+(?:,\\d{3})*(?:\\.\\d{2})?(?:\\s+(?:billion|million|thousand|trillion))?'\n",
    "    entities['money'].extend(re.findall(money_pattern, text, re.IGNORECASE))\n",
    "    \n",
    "    # Extract percentages\n",
    "    percentage_pattern = r'\\d+(?:\\.\\d+)?%'\n",
    "    entities['percentages'].extend(re.findall(percentage_pattern, text))\n",
    "    \n",
    "    # Extract email addresses\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    entities['emails'].extend(re.findall(email_pattern, text))\n",
    "    \n",
    "    # Extract phone numbers (US format)\n",
    "    phone_pattern = r'\\b(?:\\+?1[-.\\s]?)?\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}\\b'\n",
    "    entities['phone_numbers'].extend(re.findall(phone_pattern, text))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Apply custom entity extraction\n",
    "custom_entities = extract_custom_entities(text)\n",
    "\n",
    "print(\"Custom Entity Extraction Results:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for entity_type, entity_list in custom_entities.items():\n",
    "    if entity_list:\n",
    "        print(f\"\\n{entity_type.upper()}:\")\n",
    "        for entity in entity_list:\n",
    "            print(f\"  - {entity}\")\n",
    "    else:\n",
    "        print(f\"\\n{entity_type.upper()}: None found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b902b44",
   "metadata": {},
   "source": [
    "## Entity Types Explanation\n",
    "\n",
    "### NLTK Entity Types:\n",
    "- **PERSON**: Names of people\n",
    "- **ORGANIZATION**: Companies, agencies, institutions  \n",
    "- **GPE**: Geopolitical entities (countries, cities, states)\n",
    "- **LOCATION**: Non-GPE locations, mountain ranges, bodies of water\n",
    "- **FACILITY**: Buildings, airports, highways, bridges, etc.\n",
    "- **GSP**: Geopolitical entities, locations, facilities\n",
    "\n",
    "### spaCy Entity Types (More Comprehensive):\n",
    "- **PERSON**: People, including fictional\n",
    "- **NORP**: Nationalities or religious or political groups\n",
    "- **FAC**: Buildings, airports, highways, bridges, etc.\n",
    "- **ORG**: Companies, agencies, institutions, etc.\n",
    "- **GPE**: Countries, cities, states\n",
    "- **LOC**: Non-GPE locations, mountain ranges, bodies of water\n",
    "- **PRODUCT**: Objects, vehicles, foods, etc. (not services)\n",
    "- **EVENT**: Named hurricanes, battles, wars, sports events, etc.\n",
    "- **WORK_OF_ART**: Titles of books, songs, etc.\n",
    "- **LAW**: Named documents made into laws\n",
    "- **LANGUAGE**: Any named language\n",
    "- **DATE**: Absolute or relative dates or periods\n",
    "- **TIME**: Times smaller than a day\n",
    "- **PERCENT**: Percentage, including \"%\"\n",
    "- **MONEY**: Monetary values, including unit\n",
    "- **QUANTITY**: Measurements, as of weight or distance\n",
    "- **ORDINAL**: \"first\", \"second\", etc.\n",
    "- **CARDINAL**: Numerals that do not fall under another type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19610e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Text Analysis:\n",
      "==================================================\n",
      "\n",
      "Dr. John Smith, the CEO of TechCorp Inc., announced that their new headquarters in San Francisco \n",
      "will open on December 15, 2024. The project cost $250 million and is expected to increase \n",
      "productivity by 35%. You can contact him at john.smith@techcorp.com or call (555) 123-4567. \n",
      "The company, founded in 1995, has offices in New York, London, and Tokyo. Their latest product, \n",
      "the SuperWidget 3000, won the Innovation Award at the Tech Conference 2024.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "NLTK Results:\n",
      "  John Smith (PERSON)\n",
      "  CEO (ORGANIZATION)\n",
      "  TechCorp Inc. (ORGANIZATION)\n",
      "  San Francisco (GPE)\n",
      "  john.smith (ORGANIZATION)\n",
      "  New York (GPE)\n",
      "  London (GPE)\n",
      "  Tokyo (GPE)\n",
      "  SuperWidget (ORGANIZATION)\n",
      "  Innovation Award (ORGANIZATION)\n",
      "  Tech (ORGANIZATION)\n",
      "\n",
      "Custom Extraction Results:\n",
      "  dates: ['December 15, 2024']\n",
      "  money: ['$250 million']\n",
      "  percentages: ['35%']\n",
      "  emails: ['john.smith@techcorp.com']\n",
      "  phone_numbers: ['555) 123-4567']\n",
      "  John Smith (PERSON)\n",
      "  CEO (ORGANIZATION)\n",
      "  TechCorp Inc. (ORGANIZATION)\n",
      "  San Francisco (GPE)\n",
      "  john.smith (ORGANIZATION)\n",
      "  New York (GPE)\n",
      "  London (GPE)\n",
      "  Tokyo (GPE)\n",
      "  SuperWidget (ORGANIZATION)\n",
      "  Innovation Award (ORGANIZATION)\n",
      "  Tech (ORGANIZATION)\n",
      "\n",
      "Custom Extraction Results:\n",
      "  dates: ['December 15, 2024']\n",
      "  money: ['$250 million']\n",
      "  percentages: ['35%']\n",
      "  emails: ['john.smith@techcorp.com']\n",
      "  phone_numbers: ['555) 123-4567']\n"
     ]
    }
   ],
   "source": [
    "# Let's test with a more complex example\n",
    "complex_text = \"\"\"\n",
    "Dr. John Smith, the CEO of TechCorp Inc., announced that their new headquarters in San Francisco \n",
    "will open on December 15, 2024. The project cost $250 million and is expected to increase \n",
    "productivity by 35%. You can contact him at john.smith@techcorp.com or call (555) 123-4567. \n",
    "The company, founded in 1995, has offices in New York, London, and Tokyo. Their latest product, \n",
    "the SuperWidget 3000, won the Innovation Award at the Tech Conference 2024.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Complex Text Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(complex_text)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Apply NLTK NER\n",
    "print(\"\\nNLTK Results:\")\n",
    "nltk_complex = nltk_ner(complex_text)\n",
    "for entity in nltk_complex:\n",
    "    if hasattr(entity, 'label'):\n",
    "        entity_name = ' '.join([child[0] for child in entity])\n",
    "        print(f\"  {entity_name} ({entity.label()})\")\n",
    "\n",
    "# Apply custom extraction\n",
    "print(\"\\nCustom Extraction Results:\")\n",
    "custom_complex = extract_custom_entities(complex_text)\n",
    "for entity_type, entities in custom_complex.items():\n",
    "    if entities:\n",
    "        print(f\"  {entity_type}: {entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290e65b",
   "metadata": {},
   "source": [
    "## Key Takeaways and Applications\n",
    "\n",
    "### When to use each method:\n",
    "\n",
    "1. **NLTK NER**:\n",
    "   - Good for basic NER tasks\n",
    "   - Suitable for educational purposes\n",
    "   - Limited entity types\n",
    "   - Free and easy to use\n",
    "\n",
    "2. **spaCy NER**:\n",
    "   - More accurate and comprehensive\n",
    "   - Better for production applications\n",
    "   - Supports more entity types\n",
    "   - Industrial-strength performance\n",
    "\n",
    "3. **Custom Extraction**:\n",
    "   - Perfect for domain-specific entities\n",
    "   - When you need very specific patterns\n",
    "   - Complement to other methods\n",
    "   - Full control over extraction logic\n",
    "\n",
    "### Real-world Applications:\n",
    "- **Information Extraction**: Extract structured data from unstructured text\n",
    "- **Content Analysis**: Analyze news articles, social media posts\n",
    "- **Customer Service**: Extract customer information from emails\n",
    "- **Legal Documents**: Identify parties, dates, amounts in contracts\n",
    "- **Medical Records**: Extract patient information, medications, conditions\n",
    "- **Financial Analysis**: Extract company names, financial figures from reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
